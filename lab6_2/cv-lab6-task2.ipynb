{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа 6.2. Сегментация изображений с помощью сверточных нейронных сетей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Работу выполнил:<span style=\"color:blue\"> {ваше имя и фамилия}</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сделанную лабораторную работу отправляйте через [ФОРМУ](https://vyatsu-my.sharepoint.com/:f:/g/personal/usr09019_vyatsu_ru/EpSy8Xu4FxhMklHgj0NBX-4B1VnXTBIs4-D3Oi74j0wcGQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Необходимо выполнить сравнение моделей семантической сегментации FCN-ResNet101 и DeepLabv3 по следующим параметрам:\n",
    "1. время инференса на GPU;\n",
    "2. время инференса на CPU;\n",
    "3. размер модели.\n",
    "\n",
    "Результаты сравнения представить в виде диаграмм."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже приводится пример кода, позволяющего выполнить сгементацию изображения при помощи модели FCN-ResNet101."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SrL47MttOLS3"
   },
   "source": [
    "from torchvision import models\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "V3Jwg9JJOLTE"
   },
   "source": [
    "# Load model\n",
    "fcn = models.segmentation.fcn_resnet101(pretrained=True).eval()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LqB1PotzOLTF",
    "outputId": "2fef74c0-eba7-4dc5-a35a-b238432ee2c3"
   },
   "source": [
    "img = Image.open('./pict.jpg')\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2mUcSMIMOLTG",
    "outputId": "88cc5e5d-2c37-41e6-ef9d-72ca9237efd8"
   },
   "source": [
    "# Apply the transformations needed\n",
    "trf = T.Compose([T.Resize(256),\n",
    "            #T.CenterCrop(224),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean = [0.485, 0.456, 0.406],\n",
    "                std = [0.229, 0.224, 0.225])])\n",
    "inp = trf(img).unsqueeze(0)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ViY8viSLOLTH"
   },
   "source": [
    "# Pass the input through the net\n",
    "out = fcn(inp)['out']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3eVi7mJZOLTH"
   },
   "source": [
    "# We take a max index for each pixel position, which represents the class\n",
    "om = torch.argmax(out.squeeze(), dim=0).detach().cpu().numpy()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "EqMKMqdWOLTH"
   },
   "source": [
    "# Define the helper function\n",
    "def decode_segmap(image, nc=21):\n",
    "    label_colors = np.array([(0, 0, 0),  # 0=background\n",
    "                # 1=aeroplane, 2=bicycle, 3=bird, 4=boat, 5=bottle\n",
    "                (128, 0, 0), (0, 128, 0), (128, 128, 0), (0, 0, 128), (128, 0, 128),\n",
    "                # 6=bus, 7=car, 8=cat, 9=chair, 10=cow\n",
    "                (0, 128, 128), (128, 128, 128), (64, 0, 0), (192, 0, 0), (64, 128, 0),\n",
    "                # 11=dining table, 12=dog, 13=horse, 14=motorbike, 15=person\n",
    "                (192, 128, 0), (64, 0, 128), (192, 0, 128), (64, 128, 128), (192, 128, 128),\n",
    "                # 16=potted plant, 17=sheep, 18=sofa, 19=train, 20=tv/monitor\n",
    "                (0, 64, 0), (128, 64, 0), (0, 192, 0), (128, 192, 0), (0, 64, 128)])\n",
    "    r = np.zeros_like(image).astype(np.uint8)\n",
    "    g = np.zeros_like(image).astype(np.uint8)\n",
    "    b = np.zeros_like(image).astype(np.uint8)\n",
    "    \n",
    "    for l in range(0, nc):\n",
    "        idx = image == l\n",
    "        r[idx] = label_colors[l, 0]\n",
    "        g[idx] = label_colors[l, 1]\n",
    "        b[idx] = label_colors[l, 2]\n",
    "    \n",
    "    rgb = np.stack([r, g, b], axis=2)\n",
    "    return rgb"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "rgb = decode_segmap(om)\n",
    "plt.imshow(rgb)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "image_classification_using_transfer_learning_in_pytorch.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "39dc1b0906487b45ba344ffeedd791fdcc86df127220ba63f0709de5586920fd"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
